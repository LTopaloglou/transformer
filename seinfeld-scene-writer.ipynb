{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb2b426",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:47.037756Z",
     "iopub.status.busy": "2024-05-10T12:12:47.037367Z",
     "iopub.status.idle": "2024-05-10T12:12:47.784679Z",
     "shell.execute_reply": "2024-05-10T12:12:47.783663Z"
    },
    "papermill": {
     "duration": 0.757706,
     "end_time": "2024-05-10T12:12:47.787588",
     "exception": false,
     "start_time": "2024-05-10T12:12:47.029882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/seinfeld-text-corpus/corpus.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39dbcf1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:47.801562Z",
     "iopub.status.busy": "2024-05-10T12:12:47.800733Z",
     "iopub.status.idle": "2024-05-10T12:12:51.353273Z",
     "shell.execute_reply": "2024-05-10T12:12:51.352379Z"
    },
    "papermill": {
     "duration": 3.561783,
     "end_time": "2024-05-10T12:12:51.355527",
     "exception": false,
     "start_time": "2024-05-10T12:12:47.793744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import pytorch\n",
    "from torch.torch_version import Version\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#Set up pytorch to run on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    processor = 'cuda'\n",
    "else:\n",
    "    processor = 'cpu'\n",
    "device = torch.device(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b2b1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:51.368849Z",
     "iopub.status.busy": "2024-05-10T12:12:51.368365Z",
     "iopub.status.idle": "2024-05-10T12:12:51.552914Z",
     "shell.execute_reply": "2024-05-10T12:12:51.551789Z"
    },
    "papermill": {
     "duration": 0.193517,
     "end_time": "2024-05-10T12:12:51.555222",
     "exception": false,
     "start_time": "2024-05-10T12:12:51.361705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', '\\\\', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '~', '\\xa0', '¿', 'à', 'è', 'é', 'í', 'ï', 'ñ', 'ó', 'ÿ', '–', '—', '…']\n",
      "int. comedy club – night\n",
      "(jerry is on stage, performing.)\n",
      "jerry: do you know what this is all about?\n"
     ]
    }
   ],
   "source": [
    "#Create vocabulary\n",
    "scripts = open(\"/kaggle/input/seinfeld-text-corpus/corpus.txt\").read().lower().replace('[','').replace(']','')\n",
    "\n",
    "chars = sorted(list(set(scripts)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(chars)\n",
    "print(scripts[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b4636a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:51.568656Z",
     "iopub.status.busy": "2024-05-10T12:12:51.568306Z",
     "iopub.status.idle": "2024-05-10T12:12:51.575346Z",
     "shell.execute_reply": "2024-05-10T12:12:51.574461Z"
    },
    "papermill": {
     "duration": 0.016067,
     "end_time": "2024-05-10T12:12:51.577540",
     "exception": false,
     "start_time": "2024-05-10T12:12:51.561473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 39, 49]\n",
      "leo\n"
     ]
    }
   ],
   "source": [
    "#Encoding & Decoding strings into numbers\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "def encode(st):\n",
    "    output = []\n",
    "    for ch in st:\n",
    "        output.append(stoi[ch])\n",
    "    return output\n",
    "\n",
    "def decode(lis):\n",
    "    output = \"\"\n",
    "    for num in lis:\n",
    "        output = output + itos[num]\n",
    "    return output\n",
    "print(encode(\"leo\"))\n",
    "print(decode(encode(\"leo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fc4ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:51.590785Z",
     "iopub.status.busy": "2024-05-10T12:12:51.590295Z",
     "iopub.status.idle": "2024-05-10T12:12:51.594939Z",
     "shell.execute_reply": "2024-05-10T12:12:51.594009Z"
    },
    "papermill": {
     "duration": 0.013559,
     "end_time": "2024-05-10T12:12:51.596950",
     "exception": false,
     "start_time": "2024-05-10T12:12:51.583391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hyperparams\n",
    "block_size = 64 #The max number of characters of context used. seq <= block_size always\n",
    "N = 10 #Number of self-attention & feed forward blocks stacked\n",
    "d_model = 80 #Dimensions of the embedding vectors in the model\n",
    "h = 8 #Number of heads in self-attention\n",
    "d_hidden = d_model * 4 #Number of hidden nodes in feed forward networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14adfa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:51.610537Z",
     "iopub.status.busy": "2024-05-10T12:12:51.610152Z",
     "iopub.status.idle": "2024-05-10T12:12:51.640154Z",
     "shell.execute_reply": "2024-05-10T12:12:51.639097Z"
    },
    "papermill": {
     "duration": 0.039286,
     "end_time": "2024-05-10T12:12:51.642279",
     "exception": false,
     "start_time": "2024-05-10T12:12:51.602993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#I am using variable names defined in \"Attention Is All You Need\" for simplicity.\n",
    "\n",
    "#Define a single Scaled Dot-Product Attention head. I am simplifying it by enforcing d_k = d_v\n",
    "class Attention(nn.Module):\n",
    "\n",
    "  def __init__(self, d_k, mask):\n",
    "    super().__init__()\n",
    "    self.mask = mask\n",
    "    self.d_k = d_k\n",
    "    self.register_buffer('lowerTriangle', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "  def forward(self, Q, K, V):\n",
    "    #Takes in vectors of Queries, Keys & Values. Queries, Keys & Values have dimension seq x d_k\n",
    "    if (Q.shape[1] != self.d_k or K.shape[1] != self.d_k or V.shape[1] != self.d_k):\n",
    "      raise Exception('Invalid Query, Key or Value Dimensions')\n",
    "    seq = Q.shape[0]\n",
    "    #First take the dot product of Queries & Keys. Weight has dimensions seq x seq\n",
    "    weight = Q @ K.transpose(0, 1)\n",
    "    #Now scale by 1/sqrt(d_k)\n",
    "    weight = weight  * (self.d_k**-0.5)\n",
    "    #Mask everything not in the lower triangular of weight\n",
    "    if (self.mask):\n",
    "      weight = weight.masked_fill(self.lowerTriangle[:seq, :seq]== 0, float('-inf'))\n",
    "    #Now apply softmax in the dimension of the rows\n",
    "    weight = weight.softmax(1)\n",
    "    #Finally, multiply values by weights to get the outputs\n",
    "    out = weight @ V # [seq, seq] x [seq, d_k] = [seq, d_k]\n",
    "    return out\n",
    "\n",
    "#Define a Multi-Head Attention layer. As in the paper, I am setting d_k = d_model/h\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, h, mask):\n",
    "    super().__init__()\n",
    "    self.mask = mask\n",
    "    self.d_model = d_model\n",
    "    self.h = h\n",
    "    self.d_k = int(d_model/h)\n",
    "    if (self.d_k != d_model/h):\n",
    "      raise Exception('Invalid Dimensions Provided') #Ensure valid dimensions\n",
    "    self.W_O = nn.Linear(h*self.d_k, d_model, bias=False) #Output linear layer\n",
    "    self.W_Q = nn.ModuleList() #The h different Query linear layers\n",
    "    self.W_K = nn.ModuleList() #The h different Key linear layers\n",
    "    self.W_V = nn.ModuleList() #The h different Value linear layers\n",
    "    self.Att = Attention(self.d_k, mask) #I think (?) only 1 attention layer is needed since no backprop happens TODO: VERIFY\n",
    "    for i in range(h):\n",
    "      #Initialize all h linear layers for Q, K, V\n",
    "      self.W_Q.append(nn.Linear(d_model, self.d_k, bias=False))\n",
    "      self.W_K.append(nn.Linear(d_model, self.d_k, bias=False))\n",
    "      self.W_V.append(nn.Linear(d_model, self.d_k, bias=False)) #TODO: Instead of Linear layers, just create Matrices\n",
    "\n",
    "  def forward(self, Q, K, V):\n",
    "    #The inputs are Queries, Keys and Vectors which each have size seq x d_model\n",
    "    if (Q.shape[1] != self.d_model or K.shape[1] != self.d_model or V.shape[1] != self.d_model):\n",
    "      raise Exception('Invalid Query, Key or Value Dimensions')\n",
    "    heads = []\n",
    "    for i in range(self.h):\n",
    "      queries = self.W_Q[i](Q)\n",
    "      keys = self.W_K[i](K)\n",
    "      values = self.W_V[i](V)\n",
    "      #At this point, queries keys & values have dimensions seq x d_k\n",
    "      heads.append(self.Att.forward(queries, keys, values))\n",
    "    out = torch.cat(heads, 1) #The output has the same dimension as all the inputs: seq x d_model\n",
    "    out = self.W_O(out)\n",
    "    return out\n",
    "\n",
    "#Define a Feed Forward Network\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_hidden):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential(\n",
    "        nn.Linear(d_model, d_hidden, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden, d_model, bias=True)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.network(x)\n",
    "    return x\n",
    "\n",
    "#Define Layer Normalization:\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model):\n",
    "    super().__init__()\n",
    "    self.epsilon = 1e-5\n",
    "    self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "    self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "  def __call__(self, x):\n",
    "    mean = x.mean(1, keepdim=True) #Mean across the layer i.e. the column\n",
    "    variance = x.var(1, keepdim=True) #Mean across the layer i.e. column\n",
    "    norm = (x - mean) / torch.sqrt(variance + self.epsilon) #Normalize\n",
    "    out = self.gamma * norm + self.beta #Scale by gamma, add beta to achieve var= gamma, mean = beta\n",
    "    return out\n",
    "\n",
    "\n",
    "#Define an Block of Multi Head Self-Attention with a Residual Connection & Layer Normalization\n",
    "class NormalizedSelfAttention(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, h, mask):\n",
    "    super().__init__()\n",
    "    self.MHA = MultiHeadAttention(d_model, h, mask)\n",
    "    self.norm = LayerNorm(d_model)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = x + self.MHA(x, x, x)\n",
    "    x = self.norm(x)\n",
    "    return x\n",
    "\n",
    "#Define a block of a Feed Forward Network with a Residual Connection & Layer Normalization\n",
    "class NormalizedFeedForward(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_hidden):\n",
    "    super().__init__()\n",
    "    self.FF = FeedForward(d_model, d_hidden)\n",
    "    self.norm = LayerNorm(d_model)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = x + self.FF(x)\n",
    "    x = self.norm(x)\n",
    "    return x\n",
    "\n",
    "#Define a stand-alone Decoder block with N self-attention and feed forward blocks (without embeddings or softmax)\n",
    "#Note that the self attention is Masked because this is a Decoder\n",
    "class StandAloneDecoder(nn.Module):\n",
    "\n",
    "  def __init__(self, N, d_model, h, d_hidden):\n",
    "    super().__init__()\n",
    "    self.network = nn.Sequential()\n",
    "    for i in range(N):\n",
    "      self.network.append(NormalizedSelfAttention(d_model, h, True))\n",
    "      self.network.append(NormalizedFeedForward(d_model, d_hidden))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.network(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae908c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:51.655231Z",
     "iopub.status.busy": "2024-05-10T12:12:51.654953Z",
     "iopub.status.idle": "2024-05-10T12:12:53.051309Z",
     "shell.execute_reply": "2024-05-10T12:12:53.050176Z"
    },
    "papermill": {
     "duration": 1.40546,
     "end_time": "2024-05-10T12:12:53.053805",
     "exception": false,
     "start_time": "2024-05-10T12:12:51.648345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split up training & test data\n",
    "data = torch.tensor(encode(scripts), dtype=torch.long).to(device)\n",
    "cutoff = int(0.9 * len(scripts))\n",
    "train_data = data[:cutoff]\n",
    "test_data = data[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b55238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.067656Z",
     "iopub.status.busy": "2024-05-10T12:12:53.067291Z",
     "iopub.status.idle": "2024-05-10T12:12:53.100143Z",
     "shell.execute_reply": "2024-05-10T12:12:53.098961Z"
    },
    "papermill": {
     "duration": 0.042051,
     "end_time": "2024-05-10T12:12:53.102220",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.060169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor([35, 46, 38, 53, 54, 39, 43, 48, 11,  2,  0, 41, 39, 49, 52, 41, 39, 27,\n",
      "         1, 57, 39,  1, 38, 43, 38,  1, 35,  1, 37, 52, 49, 53, 53, 57, 49, 52,\n",
      "        38,  1, 50, 55, 60, 60, 46, 39,  1, 54, 49, 41, 39, 54, 42, 39, 52, 13,\n",
      "         1, 11, 43, 48,  1, 36, 39, 38, 11, 15], device='cuda:0')\n",
      "torch.Size([64])\n",
      "tensor([46, 38, 53, 54, 39, 43, 48, 11,  2,  0, 41, 39, 49, 52, 41, 39, 27,  1,\n",
      "        57, 39,  1, 38, 43, 38,  1, 35,  1, 37, 52, 49, 53, 53, 57, 49, 52, 38,\n",
      "         1, 50, 55, 60, 60, 46, 39,  1, 54, 49, 41, 39, 54, 42, 39, 52, 13,  1,\n",
      "        11, 43, 48,  1, 36, 39, 38, 11, 15,  1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Load training data\n",
    "#torch.manual_seed(2131)\n",
    "\n",
    "def get_sequence(split):\n",
    "    #Returns a sequence of block_size training examples\n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    ix = torch.randint(len(data)-block_size, (1,))\n",
    "    x = data[ix:ix+block_size].to(device)\n",
    "    y = data[ix+1:ix+block_size+1].to(device)\n",
    "    return x,y\n",
    "    \n",
    "\n",
    "x_train, y_train = get_sequence('train')\n",
    "print(x_train.shape)\n",
    "print(x_train)\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7bd2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.116947Z",
     "iopub.status.busy": "2024-05-10T12:12:53.116631Z",
     "iopub.status.idle": "2024-05-10T12:12:53.126932Z",
     "shell.execute_reply": "2024-05-10T12:12:53.125946Z"
    },
    "papermill": {
     "duration": 0.020287,
     "end_time": "2024-05-10T12:12:53.129227",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.108940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define the Decoder model w/ input & positional embeddings\n",
    "class DecoderWithEmbeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #TODO: change all these to parameters for the DecoderWithEmbedding object?\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(block_size, d_model) #TODO: change this to as seen in paper\n",
    "        self.decoders = StandAloneDecoder(N, d_model, h, d_hidden)\n",
    "        self.unembed = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, chars, target=None):\n",
    "        tok = self.token_embed(chars)\n",
    "        pos = self.pos_embed(torch.arange(chars.shape[0]).to(device))\n",
    "        x = tok + pos\n",
    "        x = self.decoders(x)\n",
    "        logits = self.unembed(x)\n",
    "        \n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, target)  #Are the dimensions of logits right here?\n",
    "            \n",
    "        return logits, loss\n",
    "    \n",
    "    def sample(self, chars, output_len):\n",
    "        for i in range(output_len):\n",
    "            logits, loss = self(chars[-8:])\n",
    "            logits = logits[-1,:]\n",
    "            probs = F.softmax(logits, dim=0)\n",
    "            next_char = torch.multinomial(probs, num_samples=1)\n",
    "            chars = torch.cat((chars, next_char), dim=0)\n",
    "        return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2469376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.142793Z",
     "iopub.status.busy": "2024-05-10T12:12:53.142482Z",
     "iopub.status.idle": "2024-05-10T12:12:53.206729Z",
     "shell.execute_reply": "2024-05-10T12:12:53.205436Z"
    },
    "papermill": {
     "duration": 0.073515,
     "end_time": "2024-05-10T12:12:53.208964",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.135449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params:\n",
      "792717\n"
     ]
    }
   ],
   "source": [
    "m = DecoderWithEmbeddings()\n",
    "model = m.to(device)\n",
    "print(\"Number of params:\")\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2df75e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.223792Z",
     "iopub.status.busy": "2024-05-10T12:12:53.222726Z",
     "iopub.status.idle": "2024-05-10T12:12:53.229651Z",
     "shell.execute_reply": "2024-05-10T12:12:53.228684Z"
    },
    "papermill": {
     "duration": 0.0167,
     "end_time": "2024-05-10T12:12:53.231797",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.215097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_sequence(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b1004f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.246357Z",
     "iopub.status.busy": "2024-05-10T12:12:53.246067Z",
     "iopub.status.idle": "2024-05-10T12:12:53.252493Z",
     "shell.execute_reply": "2024-05-10T12:12:53.251659Z"
    },
    "papermill": {
     "duration": 0.016298,
     "end_time": "2024-05-10T12:12:53.254368",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.238070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(training_iters, eval_interval, eval_iters, optimizer):\n",
    "    for iter in range(training_iters):\n",
    "        #Evaluate training loss\n",
    "        if iter % eval_interval == 0 or iter == training_iters - 1:\n",
    "            losses = estimate_loss(eval_iters)\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "        #Get a training example\n",
    "        x,y = get_sequence('train')\n",
    "\n",
    "        #evaluate loss\n",
    "        logits, loss = model(x, y)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580aa7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T12:12:53.267280Z",
     "iopub.status.busy": "2024-05-10T12:12:53.267005Z",
     "iopub.status.idle": "2024-05-10T14:11:45.996292Z",
     "shell.execute_reply": "2024-05-10T14:11:45.995211Z"
    },
    "papermill": {
     "duration": 7132.74549,
     "end_time": "2024-05-10T14:11:46.005767",
     "exception": false,
     "start_time": "2024-05-10T12:12:53.260277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.5437, val loss 4.5424\n",
      "step 10000: train loss 1.7573, val loss 1.7923\n",
      "step 20000: train loss 1.6154, val loss 1.6716\n",
      "step 30000: train loss 1.5550, val loss 1.6219\n",
      "step 40000: train loss 1.5329, val loss 1.5727\n",
      "step 50000: train loss 1.4876, val loss 1.5509\n",
      "step 60000: train loss 1.4679, val loss 1.5239\n",
      "step 70000: train loss 1.4516, val loss 1.5031\n",
      "step 80000: train loss 1.4489, val loss 1.5107\n",
      "step 90000: train loss 1.4312, val loss 1.4773\n",
      "step 99999: train loss 1.4310, val loss 1.4934\n"
     ]
    }
   ],
   "source": [
    "#Setup optimizer, train 100000 steps.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train(100000, 10000, 1000, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f8d59e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T14:11:46.023671Z",
     "iopub.status.busy": "2024-05-10T14:11:46.022960Z",
     "iopub.status.idle": "2024-05-10T14:27:00.260062Z",
     "shell.execute_reply": "2024-05-10T14:27:00.258991Z"
    },
    "papermill": {
     "duration": 914.257292,
     "end_time": "2024-05-10T14:27:00.270972",
     "exception": false,
     "start_time": "2024-05-10T14:11:46.013680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.4576, val loss 1.5204\n",
      "step 1000: train loss 1.3725, val loss 1.4404\n",
      "step 2000: train loss 1.3531, val loss 1.4258\n",
      "step 3000: train loss 1.3443, val loss 1.4262\n",
      "step 4000: train loss 1.3232, val loss 1.4023\n",
      "step 5000: train loss 1.3381, val loss 1.4236\n",
      "step 6000: train loss 1.3361, val loss 1.4172\n",
      "step 7000: train loss 1.3213, val loss 1.3831\n",
      "step 8000: train loss 1.3216, val loss 1.3807\n",
      "step 9000: train loss 1.3008, val loss 1.4067\n",
      "step 9999: train loss 1.3192, val loss 1.3886\n"
     ]
    }
   ],
   "source": [
    "#Decay training rate, train another 10000 steps.\n",
    "learning_rate = 1e-4\n",
    "optimizer.param_groups[0]['lr'] = learning_rate\n",
    "train(10000, 1000, 500, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83dfd5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T14:27:00.289746Z",
     "iopub.status.busy": "2024-05-10T14:27:00.289358Z",
     "iopub.status.idle": "2024-05-10T14:30:26.218871Z",
     "shell.execute_reply": "2024-05-10T14:30:26.217767Z"
    },
    "papermill": {
     "duration": 205.950113,
     "end_time": "2024-05-10T14:30:26.229814",
     "exception": false,
     "start_time": "2024-05-10T14:27:00.279701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.3207, val loss 1.3982\n"
     ]
    }
   ],
   "source": [
    "#Estimate loss to a high accuracy\n",
    "train(1, 10, 5000, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa41999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T14:30:26.249324Z",
     "iopub.status.busy": "2024-05-10T14:30:26.248499Z",
     "iopub.status.idle": "2024-05-10T14:30:39.961160Z",
     "shell.execute_reply": "2024-05-10T14:30:39.959976Z"
    },
    "papermill": {
     "duration": 13.724688,
     "end_time": "2024-05-10T14:30:39.963413",
     "exception": false,
     "start_time": "2024-05-10T14:30:26.238725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(kramer at stries hold to jerry) you know she's breakunts) give her, she's, he takes a greater.\n",
      "(kramer walks up. i thought is understand, anda: good, i know what you got out with the bost and manute omen?!\n",
      "madevitys\n",
      "(morty smokfardayl undecturioil) oh, i had a lofer party is harness.)\n",
      "george: ..ah...... churtely.)\n",
      "kramer: hello.\n",
      "jerry: you reached very ranies off,  pricked fashing sneak guss\n",
      "mary: okay. asself a): lad jap cleart.) now, you gotta go and he talks-bootheried with the side out peer\n"
     ]
    }
   ],
   "source": [
    "#Generate a script from the model\n",
    "start = torch.tensor(encode('\\n')).to(device)\n",
    "print(decode(model.sample(start, 500).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e6c5a",
   "metadata": {
    "papermill": {
     "duration": 0.008532,
     "end_time": "2024-05-10T14:30:39.980748",
     "exception": false,
     "start_time": "2024-05-10T14:30:39.972216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Highscore:\n",
    "step 0: train loss 1.2801, val loss 1.3542\n",
    "# Hyperparams:\n",
    "block_size = 64 \n",
    "N = 8 \n",
    "d_model = 80 \n",
    "h = 8 \n",
    "d_hidden = d_model * 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c41b9770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T14:30:40.000028Z",
     "iopub.status.busy": "2024-05-10T14:30:39.999183Z",
     "iopub.status.idle": "2024-05-10T14:30:40.046212Z",
     "shell.execute_reply": "2024-05-10T14:30:40.045155Z"
    },
    "papermill": {
     "duration": 0.059351,
     "end_time": "2024-05-10T14:30:40.048802",
     "exception": false,
     "start_time": "2024-05-10T14:30:39.989451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Code to save/restore model\n",
    "\n",
    "filepath = 'trained_parameters'\n",
    "torch.save(model.state_dict(), filepath)\n",
    "\n",
    "#Later to restore:\n",
    "#model.load_state_dict(torch.load(filepath))\n",
    "#model.eval()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 99201,
     "sourceId": 242881,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8277.958807,
   "end_time": "2024-05-10T14:30:41.398838",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-10T12:12:43.440031",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
